{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, make_scorer, confusion_matrix, \\\n",
    "    recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit, GroupKFold, cross_val_score\n",
    "from sklearn.metrics import auc, precision_recall_curve,accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import tree, svm, naive_bayes, neighbors\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer, OneHotEncoder,LabelEncoder\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfs = {'svm': svm.SVC(probability=True),\n",
    "        'decision_tree': tree.DecisionTreeClassifier(),\n",
    "        'naive_gaussian': naive_bayes.GaussianNB(),\n",
    "        'naive_mul': naive_bayes.MultinomialNB(),\n",
    "        'K_neighbor': neighbors.KNeighborsClassifier(),\n",
    "        'bagging_knn': BaggingClassifier(neighbors.KNeighborsClassifier(), max_samples=0.5, max_features=0.5),\n",
    "        'bagging_tree': BaggingClassifier(tree.DecisionTreeClassifier(), max_samples=0.5, max_features=0.5),\n",
    "        'random_forest': RandomForestClassifier(n_estimators=50),\n",
    "        'adaboost': AdaBoostClassifier(n_estimators=50),\n",
    "        'gradient_boost': GradientBoostingClassifier(n_estimators=50, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measure accuracy\n",
    "\n",
    "#### Confusion matrix generatioon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loop through classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and testing data collecting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### response variable -> true or false\n",
    "#### independent variable -> numerical and/or sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
      "       handle_unknown='error', n_values='auto', sparse=False)\n"
     ]
    }
   ],
   "source": [
    "aminoAcidCodes = [\"ALA\",\"ARG\",\"ASN\",\"ASP\",\"CYS\",\"GLN\",\"GLY\",\"GLU\",\"HIS\",\"ILE\",\"LEU\",\"LYS\",\n",
    "                 \"MET\",\"PHE\",\"PRO\",\"PYL\",\"SER\",\"SEC\",\"THR\",\"TRP\",\"TYR\",\"VAL\"]\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(aminoAcidCodes)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit(integer_encoded)\n",
    "print(onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoded.transform([[aminoAcidCodes.index(\"ALA\")]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 6])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le =LabelEncoder()\n",
    "le.fit([1, 2, 2, 6])\n",
    "le.transform([1, 1, 2, 6]) \n",
    "le.inverse_transform([0, 0, 1, 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data retrieving from MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pymysql\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "import matplotlib.pyplot as plt\n",
    "mysql_configure = pd.read_csv(\"Y:/Yuan/temp/mysql_connection.csv\",index_col=0)\n",
    "sql_hostname = mysql_configure.loc[\"sql_hostname\",][\"value\"]\n",
    "sql_username = mysql_configure.loc[\"sql_username\",][\"value\"]\n",
    "sql_password = mysql_configure.loc[\"sql_password\",][\"value\"]\n",
    "sql_main_database = mysql_configure.loc[\"sql_main_database\",][\"value\"]\n",
    "sql_port = mysql_configure.loc[\"sql_port\",][\"value\"]\n",
    "ssh_host = mysql_configure.loc[\"ssh_host\",][\"value\"]\n",
    "ssh_user = mysql_configure.loc[\"ssh_user\",][\"value\"]\n",
    "ssh_password = mysql_configure.loc[\"ssh_password\",][\"value\"]\n",
    "ssh_port = mysql_configure.loc[\"ssh_port\",][\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "peptidasesList = pd.read_csv(\"Y:/Yuan/temp/MCSA_EC3.4_peptidases.csv\") #for big machine\n",
    "#peptidasesList = pd.read_csv(\"/Volumes/Lab_Public/Yuan/temp/MCSA_EC3.4_peptidases.csv\") #for mac\n",
    "peptidasesList = peptidasesList[peptidasesList.iloc[:,4] == \"residue\"]\n",
    "peptidasesList = peptidasesList.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M-CSA ID</th>\n",
       "      <th>Uniprot IDs</th>\n",
       "      <th>PDB</th>\n",
       "      <th>EC</th>\n",
       "      <th>residue/reactant/product/cofactor</th>\n",
       "      <th>PDB code</th>\n",
       "      <th>chain/kegg compound</th>\n",
       "      <th>resid/chebi id</th>\n",
       "      <th>function location/name</th>\n",
       "      <th>role</th>\n",
       "      <th>role type</th>\n",
       "      <th>role group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M0587</td>\n",
       "      <td>P00727</td>\n",
       "      <td>1lam</td>\n",
       "      <td>3.4.11.1</td>\n",
       "      <td>residue</td>\n",
       "      <td>Lys</td>\n",
       "      <td>A</td>\n",
       "      <td>262.0</td>\n",
       "      <td>side_chain</td>\n",
       "      <td>electrostatic stabiliser</td>\n",
       "      <td>spectator</td>\n",
       "      <td>electrostatic interaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M0587</td>\n",
       "      <td>P00727</td>\n",
       "      <td>1lam</td>\n",
       "      <td>3.4.11.1</td>\n",
       "      <td>residue</td>\n",
       "      <td>Arg</td>\n",
       "      <td>A</td>\n",
       "      <td>336.0</td>\n",
       "      <td>side_chain</td>\n",
       "      <td>electrostatic stabiliser</td>\n",
       "      <td>spectator</td>\n",
       "      <td>electrostatic interaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M0167</td>\n",
       "      <td>Q01693</td>\n",
       "      <td>1lok</td>\n",
       "      <td>3.4.11.10</td>\n",
       "      <td>residue</td>\n",
       "      <td>His</td>\n",
       "      <td>A</td>\n",
       "      <td>97.0</td>\n",
       "      <td>side_chain</td>\n",
       "      <td>metal ligand</td>\n",
       "      <td>interaction</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M0167</td>\n",
       "      <td>Q01693</td>\n",
       "      <td>1lok</td>\n",
       "      <td>3.4.11.10</td>\n",
       "      <td>residue</td>\n",
       "      <td>His</td>\n",
       "      <td>A</td>\n",
       "      <td>97.0</td>\n",
       "      <td>side_chain</td>\n",
       "      <td>metal ligand</td>\n",
       "      <td>interaction</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M0167</td>\n",
       "      <td>Q01693</td>\n",
       "      <td>1lok</td>\n",
       "      <td>3.4.11.10</td>\n",
       "      <td>residue</td>\n",
       "      <td>His</td>\n",
       "      <td>A</td>\n",
       "      <td>97.0</td>\n",
       "      <td>side_chain</td>\n",
       "      <td>metal ligand</td>\n",
       "      <td>interaction</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  M-CSA ID Uniprot IDs   PDB         EC residue/reactant/product/cofactor  \\\n",
       "0    M0587      P00727  1lam   3.4.11.1                           residue   \n",
       "1    M0587      P00727  1lam   3.4.11.1                           residue   \n",
       "2    M0167      Q01693  1lok  3.4.11.10                           residue   \n",
       "3    M0167      Q01693  1lok  3.4.11.10                           residue   \n",
       "4    M0167      Q01693  1lok  3.4.11.10                           residue   \n",
       "\n",
       "  PDB code chain/kegg compound  resid/chebi id function location/name  \\\n",
       "0      Lys                   A           262.0             side_chain   \n",
       "1      Arg                   A           336.0             side_chain   \n",
       "2      His                   A            97.0             side_chain   \n",
       "3      His                   A            97.0             side_chain   \n",
       "4      His                   A            97.0             side_chain   \n",
       "\n",
       "                       role    role type                 role group  \n",
       "0  electrostatic stabiliser    spectator  electrostatic interaction  \n",
       "1  electrostatic stabiliser    spectator  electrostatic interaction  \n",
       "2              metal ligand  interaction                       None  \n",
       "3              metal ligand  interaction                       None  \n",
       "4              metal ligand  interaction                       None  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peptidasesList.iloc[0:5,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_by = peptidasesList.groupby([\"PDB\",\"chain/kegg compound\",\"resid/chebi id\",\"PDB code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_pos = peptidasesList[[\"PDB\",\"chain/kegg compound\",\"resid/chebi id\",\"PDB code\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_pos.iloc[:,3] = unique_pos.iloc[:,3].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDB</th>\n",
       "      <th>chain/kegg compound</th>\n",
       "      <th>resid/chebi id</th>\n",
       "      <th>PDB code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1lam</td>\n",
       "      <td>A</td>\n",
       "      <td>262.0</td>\n",
       "      <td>LYS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1lam</td>\n",
       "      <td>A</td>\n",
       "      <td>336.0</td>\n",
       "      <td>ARG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PDB chain/kegg compound  resid/chebi id PDB code\n",
       "0  1lam                   A           262.0      LYS\n",
       "1  1lam                   A           336.0      ARG"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_pos[(unique_pos.PDB ==\"1lam\") & (unique_pos[\"chain/kegg compound\"]==\"A\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def n_nearest_neighbour(PDB_ID,Chain,res_ID,n):\n",
    "    with SSHTunnelForwarder(\n",
    "        (ssh_host, int(ssh_port)),\n",
    "        ssh_username=ssh_user,\n",
    "        ssh_password=ssh_password,\n",
    "        remote_bind_address=('127.0.0.1', int(sql_port))) as tunnel:\n",
    "        print('SSH connected')\n",
    "        conn = pymysql.connect(host='127.0.0.1', user=sql_username,\n",
    "                passwd=sql_password, db=sql_main_database,\n",
    "                port=tunnel.local_bind_port)\n",
    "        try:\n",
    "            with conn as cursor: #auto commit; no close() called\n",
    "                with cursor: # close() called here\n",
    "                    sql_select = \"Select da.* FROM pdbdb.`Distance_angle2.0` da \"\n",
    "                    sql_where = \"WHERE da.pdbID = \\\"{}\\\" and da.chain = \\\"{}\\\" and da.ID_1= \\\"{}\\\";\".format(PDB_ID,Chain,res_ID)  \n",
    "                    sql = sql_select+sql_where\n",
    "                    data = pd.read_sql_query(sql, conn)\n",
    "            return(data.groupby([\"ID\"]).first().sort_values(\"Distance\").iloc[1:(n+1),])\n",
    "        except Exception as e: # catch exceptions\n",
    "            print(\"~~~~~~~~~~~~~~errors!!!\")\n",
    "            print(e)\n",
    "        finally:\n",
    "            if conn:\n",
    "                conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def One_residue_retrieval(residue_1,PDB_ID,Chain):\n",
    "    data, data_1, data_2 = None, None, None\n",
    "    with SSHTunnelForwarder(\n",
    "        (ssh_host, int(ssh_port)),\n",
    "        ssh_username=ssh_user,\n",
    "        ssh_password=ssh_password,\n",
    "        remote_bind_address=('127.0.0.1', int(sql_port))) as tunnel:\n",
    "            print('SSH connected')\n",
    "            conn = pymysql.connect(host='127.0.0.1', user=sql_username,\n",
    "                    passwd=sql_password, db=sql_main_database,\n",
    "                    port=tunnel.local_bind_port)\n",
    "            try:\n",
    "                with conn as cursor: #auto commit; no close() called\n",
    "                    with cursor: # close() called here\n",
    "                        sql_select = \"Select da.* FROM pdbdb.`Distance_angle2.0` da \"\n",
    "                        sql_where = \"WHERE da.pdbID = \\\"{}\\\" and da.chain=\\\"{}\\\" and da.ID_1 = {};\".format(PDB_ID,Chain,residue_1)    \n",
    "                        sql = sql_select+sql_where\n",
    "                        data_1 = pd.read_sql_query(sql, conn)\n",
    "                        data = data_1\n",
    "                    \n",
    "            except Exception as e: # catch exceptions\n",
    "                print(\"~~~~~~~~~~~~~~\")\n",
    "                print(e)\n",
    "            finally:\n",
    "                if conn:\n",
    "                    conn.close()\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSH connected\n"
     ]
    }
   ],
   "source": [
    "result_step1 = One_residue_retrieval(70,\"1g2i\",\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_step2 = result_step1.groupby([\"ID\"]).first() #duplicate discard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_step3 = result_step2[~result_step2.ID_2.isin([70])] # activate discard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_step4 = result_step3[result_step3[\"Res_1\"]==result_step3[\"Res_2\"]].sample(3,random_state =1) #sample nonactive site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object DataFrame.iterrows at 0x00000050D052ABA0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_step4.sample(2,random_state =1).iterrows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_neg_sample = unique_pos.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_neg_sample[\"type\"] = \"POS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,308):\n",
    "    result_step1 = One_residue_retrieval(pos_neg_sample.iloc[i,2],pos_neg_sample.iloc[i,0],pos_neg_sample.iloc[i,1])\n",
    "    result_step2 = result_step1.groupby([\"ID\"]).first() #duplicate discard\n",
    "    result_step3 = result_step2[~result_step2.ID_1.isin(unique_pos[(unique_pos.PDB ==pos_neg_sample.iloc[i,0]) & (unique_pos[\"chain/kegg compound\"]==pos_neg_sample.iloc[i,1])])] # activate discard\n",
    "    if(result_step3[result_step3[\"Res_1\"]==result_step3[\"Res_2\"]].shape[0]>1):\n",
    "        print(i,2)\n",
    "        result_step4 = result_step3[result_step3[\"Res_1\"]==result_step3[\"Res_2\"]].sample(2,random_state =1) #sample nonactive site\n",
    "        for row in result_step4.iterrows():\n",
    "            pos_neg_sample = pos_neg_sample.append({\"PDB\":row[1][0],\"chain/kegg compound\":row[1][1],\"resid/chebi id\":row[1].ID_2,\"PDB code\":row[1][5],\"type\":\"NEG\"},ignore_index=True)\n",
    "    elif result_step3[result_step3[\"Res_1\"]==result_step3[\"Res_2\"]].shape[0] == 1:\n",
    "        print(i,1)\n",
    "        result_step4 = result_step3[result_step3[\"Res_1\"]==result_step3[\"Res_2\"]]\n",
    "        print(result_step4)\n",
    "        pos_neg_sample = pos_neg_sample.append({\"PDB\":result_step4.iloc[0,0],\"chain/kegg compound\":result_step4.iloc[0,1],\"resid/chebi id\":result_step4.iloc[0,4],\"PDB code\":result_step4.iloc[0,5],\"type\":\"NEG\"},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_neg_sample_neighbor = pos_neg_sample.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Because of storing list in pandas datafram is tricky, another list will be created to stores neighbour info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbour_information_list = []\n",
    "for i in range(0,886):\n",
    "    neigh = n_nearest_neighbour(pos_neg_sample.iloc[i,0],pos_neg_sample.iloc[i,1],pos_neg_sample.iloc[i,2],5).iloc[:,5:8].values.flatten()\n",
    "    neighbour_information_list.append(np.insert(neigh,0,pos_neg_sample.iloc[i,3]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "for each_res in neighbour_information_list:\n",
    "    one_res_data = []\n",
    "    for element in each_res:\n",
    "        if isinstance(element,str):\n",
    "            one_res_data.extend(onehot_encoded.transform([[aminoAcidCodes.index(element)]])[0].tolist())\n",
    "        else:\n",
    "            one_res_data.append(element)\n",
    "    train_dataset.append(one_res_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wrong_sample = []\n",
    "for i in range(0,len(train_dataset)):\n",
    "    if(len(train_dataset[i])<100):\n",
    "        wrong_sample.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_neg_sample_neighbor[pos_neg_sample_neighbor.type == \"POS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_label =[1 for x in range(0,308)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_label.extend([2 for i in range(0,578)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "886"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_y_label = [y_label[i] for i in range(0,886) if i not in wrong_sample]\n",
    "final_y_label = np.asarray(final_y_label)\n",
    "shuffle_y_label = shuffle(final_y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_train_dataset = [train_dataset[i] for i in range(0,886) if i not in wrong_sample]\n",
    "final_train_dataset = np.vstack(np.asarray(final_train_dataset))\n",
    "shuffle_train_dataset = shuffle(final_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 13  38  84 155]\n",
      "0.579310344828\n",
      "[ 17  37  80 156]\n",
      "0.596551724138\n",
      "[ 20  43  76 149]\n",
      "0.586805555556\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train, test in skf.split(shuffle_train_dataset,shuffle_y_label):\n",
    "    clfs[\"gradient_boost\"].fit(shuffle_train_dataset[train],shuffle_y_label[train])\n",
    "    conf_mat = confusion_matrix(clfs[\"gradient_boost\"].predict(shuffle_train_dataset[test]),shuffle_y_label[test])\n",
    "    print(conf_mat.ravel())\n",
    "    print(accuracy_score(clfs[\"gradient_boost\"].predict(shuffle_train_dataset[test]),shuffle_y_label[test]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoding amino acid by its residue type (six types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### add new onehot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
      "       handle_unknown='error', n_values='auto', sparse=False)\n"
     ]
    }
   ],
   "source": [
    "amino_acid_property_by_res = {\"ALA\":1,\"ILE\":1,\"LEU\":1,\"MET\":1,\"VAL\":1,\n",
    "                      \"PHE\":2, \"TRP\":2,\"TYR\":2,\n",
    "                       \"ASN\":3,\"CYS\":3,\"GLN\":3,\"SER\":3,\"THR\":3,\n",
    "                      \"ASP\":4,\"GLU\":4,\"ARG\":5,\"HIS\":5,\"LYS\":5,\"GLY\":6,\"PRO\":6}\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform([1,2,3,4,5,6])\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit(integer_encoded)\n",
    "print(onehot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoded.transform([[amino_acid_property_by_res[\"ALA\"]-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1.training using residue type and neighbour spatial information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm\n",
      "0.626730820636\n",
      "decision_tree\n",
      "0.608246458166\n",
      "naive_gaussian\n",
      "0.607270783213\n",
      "naive_mul\n",
      "0.608433573911\n",
      "K_neighbor\n",
      "0.615236567763\n",
      "bagging_knn\n",
      "0.658994921144\n",
      "bagging_tree\n",
      "0.641780272654\n",
      "random_forest\n",
      "0.679738037958\n",
      "adaboost\n",
      "0.667080994387\n",
      "gradient_boost\n",
      "0.665904838279\n"
     ]
    }
   ],
   "source": [
    "train_dataset = []\n",
    "for each_res in neighbour_information_list:\n",
    "    one_res_data = []\n",
    "    for element in each_res:\n",
    "        if isinstance(element,str):\n",
    "            one_res_data.extend(onehot_encoded.transform([[amino_acid_property_by_res[element]-1]])[0].tolist())\n",
    "        else:\n",
    "            one_res_data.append(element)\n",
    "    train_dataset.append(one_res_data)\n",
    "wrong_sample = []\n",
    "for i in range(0,len(train_dataset)):\n",
    "    if(len(train_dataset[i])<30):\n",
    "        wrong_sample.append(i)\n",
    "\n",
    "y_label =[1 for x in range(0,308)]\n",
    "y_label.extend([2 for i in range(0,578)])\n",
    "\n",
    "final_y_label = [y_label[i] for i in range(0,886) if i not in wrong_sample]\n",
    "final_y_label = np.asarray(final_y_label)\n",
    "shuffle_y_label = shuffle(final_y_label,random_state=0)\n",
    "\n",
    "final_train_dataset = [train_dataset[i] for i in range(0,886) if i not in wrong_sample]\n",
    "final_train_dataset = np.vstack(np.asarray(final_train_dataset))\n",
    "shuffle_train_dataset = shuffle(final_train_dataset,random_state=0)\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=3)\n",
    "# for train, test in skf.split(shuffle_train_dataset,shuffle_y_label):\n",
    "#     for clf in clfs:\n",
    "#         clfs[clf].fit(shuffle_train_dataset[train],shuffle_y_label[train])\n",
    "#         conf_mat = confusion_matrix(clfs[clf].predict(shuffle_train_dataset[test]),shuffle_y_label[test])\n",
    "#         print(clf)\n",
    "#         print(accuracy_score(clfs[clf].predict(shuffle_train_dataset[test]),shuffle_y_label[test]))\n",
    "\n",
    "for clf in clfs:\n",
    "    print(clf)\n",
    "    scores = cross_val_score(clfs[clf],shuffle_train_dataset,shuffle_y_label,cv=10)\n",
    "    print(sum(scores)/10)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.training using six types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm\n",
      "0.665891472868\n",
      "decision_tree\n",
      "0.579484095162\n",
      "naive_gaussian\n",
      "0.571371291099\n",
      "naive_mul\n",
      "0.663592622294\n",
      "K_neighbor\n",
      "0.653234429297\n",
      "bagging_knn\n",
      "0.649812884256\n",
      "bagging_tree\n",
      "0.635966319166\n",
      "random_forest\n",
      "0.631368618017\n",
      "adaboost\n",
      "0.646311146752\n",
      "gradient_boost\n",
      "0.645161721465\n"
     ]
    }
   ],
   "source": [
    "train_dataset = []\n",
    "for each_res in neighbour_information_list:\n",
    "    one_res_data = []\n",
    "    for element in each_res:\n",
    "        if isinstance(element,str):\n",
    "            one_res_data.extend(onehot_encoded.transform([[amino_acid_property_by_res[element]-1]])[0].tolist())\n",
    "#         else:\n",
    "#             one_res_data.append(element)\n",
    "    train_dataset.append(one_res_data)\n",
    "\n",
    "wrong_sample = []\n",
    "for i in range(0,len(train_dataset)):\n",
    "    if(len(train_dataset[i])<30):\n",
    "        wrong_sample.append(i)\n",
    "\n",
    "y_label =[1 for x in range(0,308)]\n",
    "y_label.extend([2 for i in range(0,578)])\n",
    "\n",
    "final_y_label = [y_label[i] for i in range(0,886) if i not in wrong_sample]\n",
    "final_y_label = np.asarray(final_y_label)\n",
    "shuffle_y_label = shuffle(final_y_label,random_state=0)\n",
    "\n",
    "final_train_dataset = [train_dataset[i] for i in range(0,886) if i not in wrong_sample]\n",
    "final_train_dataset = np.vstack(np.asarray(final_train_dataset))\n",
    "shuffle_train_dataset = shuffle(final_train_dataset,random_state=0)\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=3)\n",
    "# for train, test in skf.split(shuffle_train_dataset,shuffle_y_label):\n",
    "#     for clf in clfs:\n",
    "#         clfs[clf].fit(shuffle_train_dataset[train],shuffle_y_label[train])\n",
    "#         conf_mat = confusion_matrix(clfs[clf].predict(shuffle_train_dataset[test]),shuffle_y_label[test])\n",
    "#         print(clf)\n",
    "#         print(accuracy_score(clfs[clf].predict(shuffle_train_dataset[test]),shuffle_y_label[test]))\n",
    "        \n",
    "for clf in clfs:\n",
    "    print(clf)\n",
    "    scores = cross_val_score(clfs[clf],shuffle_train_dataset,shuffle_y_label,cv=10)\n",
    "    print(sum(scores)/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "868"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_y_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import PSSM information from web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "url = 'http://3dcons.cnb.csic.es/pssm_json/1R44/A'\n",
    "file = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_decoded = json.loads(file.content)\n",
    "json_decoded[0]['iter']['2']['pssm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clfs = {'svm': svm.SVC(probability=True),\n",
    "        'decision_tree': tree.DecisionTreeClassifier(),\n",
    "        'naive_gaussian': naive_bayes.GaussianNB(),\n",
    "        'naive_mul': naive_bayes.MultinomialNB(),\n",
    "        'K_neighbor': neighbors.KNeighborsClassifier(),\n",
    "        'bagging_knn': BaggingClassifier(neighbors.KNeighborsClassifier(), max_samples=0.5, max_features=0.5),\n",
    "        'bagging_tree': BaggingClassifier(tree.DecisionTreeClassifier(), max_samples=0.5, max_features=0.5),\n",
    "        'random_forest': RandomForestClassifier(n_estimators=50),\n",
    "        'adaboost': AdaBoostClassifier(n_estimators=50),\n",
    "        'gradient_boost': GradientBoostingClassifier(n_estimators=50, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "        }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
