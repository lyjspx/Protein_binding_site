{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Bio.PDB import *\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "import time\n",
    "import configparser\n",
    "import os\n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['office_ssh', 'office_mysql']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(\"/home/yuan/Documents/config.ini\")\n",
    "config.sections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modification_site = pd.read_csv(\"/home/yuan/Documents/pdb_chain_ksites.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDB</th>\n",
       "      <th>CHAIN</th>\n",
       "      <th>SP_PRIMARY</th>\n",
       "      <th>RES_BEG</th>\n",
       "      <th>RES_END</th>\n",
       "      <th>PDB_BEG</th>\n",
       "      <th>PDB_END</th>\n",
       "      <th>SP_BEG</th>\n",
       "      <th>SP_END</th>\n",
       "      <th>Ksites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3g8c</td>\n",
       "      <td>A</td>\n",
       "      <td>P24182</td>\n",
       "      <td>1</td>\n",
       "      <td>444</td>\n",
       "      <td>1</td>\n",
       "      <td>444</td>\n",
       "      <td>1</td>\n",
       "      <td>444</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3g8c</td>\n",
       "      <td>B</td>\n",
       "      <td>P24182</td>\n",
       "      <td>1</td>\n",
       "      <td>444</td>\n",
       "      <td>1</td>\n",
       "      <td>444</td>\n",
       "      <td>1</td>\n",
       "      <td>444</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3g8d</td>\n",
       "      <td>A</td>\n",
       "      <td>P24182</td>\n",
       "      <td>1</td>\n",
       "      <td>444</td>\n",
       "      <td>1</td>\n",
       "      <td>444</td>\n",
       "      <td>1</td>\n",
       "      <td>444</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3g8d</td>\n",
       "      <td>B</td>\n",
       "      <td>P24182</td>\n",
       "      <td>1</td>\n",
       "      <td>444</td>\n",
       "      <td>1</td>\n",
       "      <td>444</td>\n",
       "      <td>1</td>\n",
       "      <td>444</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3jzf</td>\n",
       "      <td>A</td>\n",
       "      <td>P24182</td>\n",
       "      <td>22</td>\n",
       "      <td>470</td>\n",
       "      <td>1</td>\n",
       "      <td>449</td>\n",
       "      <td>1</td>\n",
       "      <td>449</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PDB CHAIN SP_PRIMARY  RES_BEG  RES_END  PDB_BEG  PDB_END  SP_BEG  SP_END  \\\n",
       "0  3g8c     A     P24182        1      444        1      444       1     444   \n",
       "1  3g8c     B     P24182        1      444        1      444       1     444   \n",
       "2  3g8d     A     P24182        1      444        1      444       1     444   \n",
       "3  3g8d     B     P24182        1      444        1      444       1     444   \n",
       "4  3jzf     A     P24182       22      470        1      449       1     449   \n",
       "\n",
       "   Ksites  \n",
       "0      27  \n",
       "1      27  \n",
       "2      27  \n",
       "3      27  \n",
       "4      27  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modification_site[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modification_site_dic = {}\n",
    "for i in range(len(modification_site)):\n",
    "    if modification_site.loc[i,\"PDB\"] not in modification_site_dic:\n",
    "        modification_site_dic[modification_site.loc[i,\"PDB\"]] = {modification_site.loc[i,\"CHAIN\"]:[modification_site.loc[i,\"Ksites\"]]}\n",
    "    elif modification_site.loc[i,\"CHAIN\"] not in modification_site_dic[modification_site.loc[i,\"PDB\"]]:\n",
    "        modification_site_dic[modification_site.loc[i,\"PDB\"]][modification_site.loc[i,\"CHAIN\"]] = [modification_site.loc[i,\"Ksites\"]]\n",
    "    else:\n",
    "        modification_site_dic[modification_site.loc[i,\"PDB\"]][modification_site.loc[i,\"CHAIN\"]].append(modification_site.loc[i,\"Ksites\"])\n",
    "for protein in modification_site_dic:\n",
    "    for chain in modification_site_dic[protein]:\n",
    "        modification_site_dic[protein][chain] = list(modification_site_dic[protein][chain])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_list = modification_site[[\"PDB\",\"CHAIN\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_list = unique_list.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDB</th>\n",
       "      <th>CHAIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4x8l</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4x8l</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PDB CHAIN\n",
       "46  4x8l     A\n",
       "47  4x8l     B"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_list.loc[unique_list[\"PDB\"]==\"4x8l\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "backbone = [\"N\",\"CA\",\"C\",\"O\"]\n",
    "aminoAcidCodes = [\"ALA\",\"ARG\",\"ASN\",\"ASP\",\"CYS\",\"GLN\",\"GLY\",\"GLU\",\"HIS\",\"ILE\",\"LEU\",\"LYS\",\n",
    "                 \"MET\",\"PHE\",\"PRO\",\"PYL\",\"SER\",\"SEC\",\"THR\",\"TRP\",\"TYR\",\"VAL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure exists: '/mnt/HD1/pdb_data/pdb3g8c.ent' \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuan/anaconda3/envs/pdbPy3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 7475.\n",
      "  PDBConstructionWarning)\n",
      "/home/yuan/anaconda3/envs/pdbPy3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 7523.\n",
      "  PDBConstructionWarning)\n",
      "/home/yuan/anaconda3/envs/pdbPy3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain A is discontinuous at line 7571.\n",
      "  PDBConstructionWarning)\n",
      "/home/yuan/anaconda3/envs/pdbPy3/lib/python3.6/site-packages/Bio/PDB/StructureBuilder.py:91: PDBConstructionWarning: WARNING: Chain B is discontinuous at line 7967.\n",
      "  PDBConstructionWarning)\n"
     ]
    }
   ],
   "source": [
    "PDB_ID = '3g8c'\n",
    "PDB = PDBList()\n",
    "retrieve_status = PDB.retrieve_pdb_file(pdb_code = PDB_ID, pdir = \"/mnt/HD1/pdb_data\", file_format=\"pdb\")\n",
    "p = PDBParser()\n",
    "structure = p.get_structure(\"X\",\"/mnt/HD1/pdb_data/\"+\"pdb\"+PDB_ID+\".ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conn = pymysql.connect(host=config[\"office_mysql\"][\"sql_host\"],user=config[\"office_mysql\"][\"sql_username\"],\n",
    "                       passwd=config[\"office_mysql\"][\"sql_password\"],\n",
    "                       db=config[\"office_mysql\"][\"sql_main_database\"],port=3306)\n",
    "for index,oneRow in unique_list.iloc[573:,].iterrows():\n",
    "    try:\n",
    "        pdbID = oneRow[\"PDB\"]\n",
    "        chainOrder = oneRow[\"CHAIN\"]\n",
    "        retrieve_status = PDB.retrieve_pdb_file(pdb_code = pdbID, pdir = \"/mnt/HD1/pdb_data\", file_format=\"pdb\")\n",
    "        if os.path.exists(retrieve_status):\n",
    "            p = PDBParser()\n",
    "            structure = p.get_structure(\"X\",\"/mnt/HD1/pdb_data/\"+\"pdb\"+pdbID+\".ent\")\n",
    "            if chainOrder in [x._id for x in list(structure.get_chains())]:\n",
    "                oneChain = pd.DataFrame(columns = [\"Seq\",\"Residue\",\"Center\",\"Direction\",\"CA_position\"])#center here means center of R group\n",
    "                if structure.header[\"resolution\"] <= 3.0:\n",
    "                    if chainOrder in [x.id for x in list(structure[0].get_chains())]:  # Chain information not in pdb file\n",
    "                        for residue in structure[0][chainOrder]:\n",
    "                            if residue.get_resname() in aminoAcidCodes:  # Only treat common amino acid\n",
    "                                if residue.get_id()[2] == \" \":  # ignore insertions\n",
    "                                    if len(list(residue.get_atoms())) > 3:\n",
    "                                        if residue.get_resname() != \"GLY\":  # Glysine as a special case\n",
    "                                            point = vectors.Vector([0, 0, 0])\n",
    "                                            for atom in residue:\n",
    "                                                if (atom.get_name() not in backbone):\n",
    "                                                    point = point + atom.get_vector()\n",
    "                                            center = point.__div__(len(residue) - 4)\n",
    "                                            cToRGroup = residue[\"CA\"].get_vector() - center\n",
    "                                            oneChain.loc[len(oneChain)] = [residue.get_id()[1], residue.get_resname(),center, cToRGroup,residue[\"CA\"].get_vector()]\n",
    "                                        else:\n",
    "                                            center = residue[\"CA\"].get_vector()\n",
    "                                            cToRGroup = center - (residue[\"C\"].get_vector() + residue[\"N\"].get_vector() + residue[\"O\"].get_vector()).__div__(3)\n",
    "                                            oneChain.loc[len(oneChain)] = [residue.get_id()[1], residue.get_resname(),center, cToRGroup,residue[\"CA\"].get_vector()]\n",
    "                distanceMatrix = pd.DataFrame(columns=list(oneChain.iloc[:, 0]), index=list(oneChain.iloc[:,0]))\n",
    "                angleMatrix = pd.DataFrame(columns=list(oneChain.iloc[:, 0]), index=list(oneChain.iloc[:, 0]))\n",
    "                numResidue = len(oneChain)\n",
    "                print(numResidue)\n",
    "                for row in range(0, numResidue):\n",
    "                    if row % 200 == 0:\n",
    "                        print(str(row) + \"th row\")\n",
    "                    for column in range(0, numResidue):#not symetric anymore\n",
    "                        coordinatesSubstraction = list(oneChain.loc[row, \"Center\"] - oneChain.loc[column, \"Center\"])\n",
    "                        pairDistance = sqrt(sum(list(map(lambda x: x * x, coordinatesSubstraction))))\n",
    "                        distanceMatrix.iloc[row, column] = pairDistance\n",
    "                        v1 = oneChain.loc[row, \"Direction\"]\n",
    "                        v2 = oneChain.loc[column,\"Center\"] - oneChain.loc[row,\"CA_position\"] \n",
    "                        if abs(pairDistance-0)>0.00001: #Exclue 0 distance, e.g. self to self\n",
    "                            pairAngle = 180 * np.arccos(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))) / np.pi\n",
    "\n",
    "                        else:\n",
    "                            pairAngle = 0\n",
    "                        angleMatrix.iloc[row, column] = pairAngle\n",
    "                        if not np.isnan(pairDistance):\n",
    "                            query = '''INSERT INTO `Distance_angle_PTM` (`pdbID`, `chain`,`ID_1`,`Res_1`,`ID_2`,`Res_2`,`Distance`,`Angle`) VALUES (%s,%s,%s,%s,%s,%s,%s,%s);'''\n",
    "                            value = (pdbID,chainOrder,oneChain.iloc[row,0],oneChain.iloc[row,1],oneChain.iloc[column,0],oneChain.iloc[column,1],float(pairDistance),float(pairAngle))\n",
    "                            conn.cursor().execute(query, value)\n",
    "                    conn.commit()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(pdbID, \"skipped\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "%%time\n",
    "conn = pymysql.connect(host=config[\"office_mysql\"][\"sql_host\"],user=config[\"office_mysql\"][\"sql_username\"],\n",
    "                       passwd=config[\"office_mysql\"][\"sql_password\"],\n",
    "                       db=config[\"office_mysql\"][\"sql_main_database\"],port=3306)\n",
    "try:\n",
    "    with conn as cursor: #auto commit; no close() called\n",
    "        with cursor: # close() called here\n",
    "            sql_select = \"Select * FROM pdbdb.Distance_angle_PTM da \"\n",
    "            sql_where = \"WHERE da.pdbID = \\\"3g8c\\\" and da.chain = \\\"A\\\" and da.ID_1=27 limit 1035;\"    \n",
    "            sql = sql_select+sql_where\n",
    "            data = pd.read_sql_query(sql, conn)\n",
    "            #print(data)\n",
    " \n",
    "except Exception as e: # catch exceptions\n",
    "    print(\"~~~~~~~~~~~~~~\")\n",
    "    print(e)\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def n_nearest_neighbour(PDB_ID,Chain,res_ID,n):\n",
    "    \n",
    "    conn = pymysql.connect(host=config[\"office_mysql\"][\"sql_host\"],user=config[\"office_mysql\"][\"sql_username\"],\n",
    "                           passwd=config[\"office_mysql\"][\"sql_password\"],\n",
    "                           db=config[\"office_mysql\"][\"sql_main_database\"],port=3306)\n",
    "    try:\n",
    "        with conn as cursor: #auto commit; no close() called\n",
    "            with cursor: # close() called here\n",
    "                sql_select = \"Select da.* FROM pdbdb.`Distance_angle_PTM` da \"\n",
    "                sql_where = \"WHERE da.pdbID = \\\"{}\\\" and da.chain = \\\"{}\\\" and da.ID_1= \\\"{}\\\";\".format(PDB_ID,Chain,res_ID)  \n",
    "                sql = sql_select+sql_where\n",
    "                data = pd.read_sql_query(sql, conn)\n",
    "        return(data.groupby([\"ID\"]).first().sort_values(\"Distance\").iloc[2:(n+2),]) #from 2 to exclude self vs self\n",
    "\n",
    "    except Exception as e: # catch exceptions\n",
    "        print(\"~~~~~~~~~~~~~~\")\n",
    "        print(e)\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_nearest_neighbour_by_seq(PDB_ID,Chain,res_ID,n):\n",
    "    if n >= res_ID:\n",
    "        return []\n",
    "    conn = pymysql.connect(host=config[\"office_mysql\"][\"sql_host\"],user=config[\"office_mysql\"][\"sql_username\"],\n",
    "                       passwd=config[\"office_mysql\"][\"sql_password\"],\n",
    "                       db=config[\"office_mysql\"][\"sql_main_database\"],port=3306)\n",
    "    try:\n",
    "        with conn as cursor: #auto commit; no close() called\n",
    "            with cursor: # close() called here\n",
    "                sql_select = \"Select da.* FROM pdbdb.`Distance_angle_PTM` da \"\n",
    "                sql_where = \"WHERE da.pdbID = \\\"{}\\\" and da.chain = \\\"{}\\\" and da.ID_1= \\\"{}\\\";\".format(PDB_ID,Chain,res_ID)  \n",
    "                sql = sql_select+sql_where\n",
    "                data = pd.read_sql_query(sql, conn)\n",
    "        head_part = data.groupby([\"ID\"]).first().iloc[(res_ID-n-1):(res_ID-1),]\n",
    "        tail_part = data.groupby([\"ID\"]).first().iloc[res_ID:(res_ID+n),]\n",
    "        return(pd.concat([head_part,tail_part])) #from 2 to exclude self vs self\n",
    "\n",
    "    except Exception as e: # catch exceptions\n",
    "        print(\"~~~~~~~~~~~~~~\")\n",
    "        print(e)\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def One_residue_retrieval(residue_1,PDB_ID,Chain):\n",
    "    data, data_1, data_2 = None, None, None\n",
    "    conn = pymysql.connect(host=config[\"office_mysql\"][\"sql_host\"],user=config[\"office_mysql\"][\"sql_username\"],\n",
    "                           passwd=config[\"office_mysql\"][\"sql_password\"],\n",
    "                           db=config[\"office_mysql\"][\"sql_main_database\"],port=3306)\n",
    "    try:\n",
    "        with conn as cursor: #auto commit; no close() called\n",
    "            with cursor: # close() called here\n",
    "                sql_select = \"Select da.* FROM pdbdb.`Distance_angle_PTM` da \"\n",
    "                sql_where = \"WHERE da.pdbID = \\\"{}\\\" and da.chain=\\\"{}\\\" and da.ID_1 = {};\".format(PDB_ID,Chain,residue_1)    \n",
    "                sql = sql_select+sql_where\n",
    "                data_1 = pd.read_sql_query(sql, conn)\n",
    "                data = data_1\n",
    "        \n",
    "    except Exception as e: # catch exceptions\n",
    "        print(\"~~~~~~~~~~~~~~\")\n",
    "        print(e)\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "        return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_FEATURE(PDBID,Chain,Seq):\n",
    "    data, data_1, data_2 = None, None, None\n",
    "    conn = pymysql.connect(host=config[\"office_mysql\"][\"sql_host\"],user=config[\"office_mysql\"][\"sql_username\"],\n",
    "                           passwd=config[\"office_mysql\"][\"sql_password\"],\n",
    "                           db=config[\"office_mysql\"][\"sql_main_database\"],port=3306)\n",
    "    try:\n",
    "        with conn as cursor: #auto commit; no close() called\n",
    "            with cursor: # close() called here\n",
    "                sql_select = \"Select da.* FROM pdbdb.`FEATURE` da \"\n",
    "                sql_where = \"WHERE da.PDBID = \\\"{}\\\" and da.Chain=\\\"{}\\\" and da.Seq = {};\".format(PDBID,Chain,Seq)    \n",
    "                sql = sql_select+sql_where\n",
    "                data_1 = pd.read_sql_query(sql, conn)\n",
    "                data = data_1[data_1[\"Component\"]==\"C\"] # currently only get C component\n",
    "        \n",
    "    except Exception as e: # catch exceptions\n",
    "        print(\"~~~~~~~~~~~~~~\")\n",
    "        print(e)\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "        return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_PSSM(PDBID,Chain,Seq):\n",
    "    data, data_1, data_2 = None, None, None\n",
    "    conn = pymysql.connect(host=config[\"office_mysql\"][\"sql_host\"],user=config[\"office_mysql\"][\"sql_username\"],\n",
    "                           passwd=config[\"office_mysql\"][\"sql_password\"],\n",
    "                           db=config[\"office_mysql\"][\"sql_main_database\"],port=3306)\n",
    "    try:\n",
    "        with conn as cursor: #auto commit; no close() called\n",
    "            with cursor: # close() called here\n",
    "                sql_select = \"Select da.* FROM pdbdb.`PSSM_uniref50` da \"\n",
    "                sql_where = \"WHERE da.PDBID = \\\"{}\\\" and da.Chain=\\\"{}\\\" and da.Seq = {};\".format(PDBID,Chain,Seq)    \n",
    "                sql = sql_select+sql_where\n",
    "                data_1 = pd.read_sql_query(sql, conn)\n",
    "                data = data_1\n",
    "        \n",
    "    except Exception as e: # catch exceptions\n",
    "        print(\"~~~~~~~~~~~~~~\")\n",
    "        print(e)\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "        return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_PSSM(PDBID,Chain,Seq):\n",
    "    data, data_1, data_2 = None, None, None\n",
    "    conn = pymysql.connect(host=config[\"office_mysql\"][\"sql_host\"],user=config[\"office_mysql\"][\"sql_username\"],\n",
    "                           passwd=config[\"office_mysql\"][\"sql_password\"],\n",
    "                           db=config[\"office_mysql\"][\"sql_main_database\"],port=3306)\n",
    "    try:\n",
    "        with conn as cursor: #auto commit; no close() called\n",
    "            with cursor: # close() called here\n",
    "                sql_select = \"Select da.* FROM pdbdb.`PSSM_uniref50` da \"\n",
    "                sql_where = \"WHERE da.PDBID = \\\"{}\\\" and da.Chain=\\\"{}\\\" and da.Seq in {};\".format(PDBID,Chain,Seq)    \n",
    "                sql = sql_select+sql_where\n",
    "                data_1 = pd.read_sql_query(sql, conn)\n",
    "                data = data_1\n",
    "        \n",
    "    except Exception as e: # catch exceptions\n",
    "        print(\"~~~~~~~~~~~~~~\")\n",
    "        print(e)\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "        return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Neigh_PSSM(PDBID,Chain,Seq,num_neigh):\n",
    "    '''\n",
    "    Retrieve redsidueâ€˜s and neighbours' PSSM.\n",
    "    No or imcomplete records will return an empty dataframe\n",
    "    '''\n",
    "    data, data_1, data_2 = None, None, None\n",
    "    conn = pymysql.connect(host=config[\"office_mysql\"][\"sql_host\"],user=config[\"office_mysql\"][\"sql_username\"],\n",
    "                           passwd=config[\"office_mysql\"][\"sql_password\"],\n",
    "                           db=config[\"office_mysql\"][\"sql_main_database\"],port=3306)\n",
    "    try:\n",
    "        with conn as cursor: #auto commit; no close() called\n",
    "            with cursor: # close() called here\n",
    "                sql_select = \"Select da.* FROM pdbdb.`PSSM_uniref50` da \"\n",
    "                sql_where = \"WHERE da.PDBID = \\\"{}\\\" and da.Chain=\\\"{}\\\" and da.Seq = {};\".format(\"XXX\",Chain,Seq)    \n",
    "                sql = sql_select+sql_where\n",
    "                data_1 = pd.read_sql_query(sql, conn)\n",
    "        if Seq <= num_neigh:\n",
    "            data = data_1\n",
    "        else:\n",
    "            with conn as cursor: #auto commit; no close() called\n",
    "                with cursor: # close() called here\n",
    "                    sql_select = \"Select da.* FROM pdbdb.`PSSM_uniref50` da \"\n",
    "                    neigh = \"(\" + \",\".join(map(str,list(range(Seq-num_neigh,Seq+num_neigh+1)))) + \")\"\n",
    "                    sql_where = \"WHERE da.PDBID = \\\"{}\\\" and da.Chain=\\\"{}\\\" and da.Seq in {};\".format(PDBID,Chain,neigh)    \n",
    "                    sql = sql_select+sql_where\n",
    "                    data_2 = pd.read_sql_query(sql, conn)\n",
    "            if data_2.shape[0] < 2*num_neigh + 1:\n",
    "                data = data_1\n",
    "            else:\n",
    "                data = data_2\n",
    "\n",
    "    except Exception as e: # catch exceptions\n",
    "        print(\"~~~~~~~~~~~~~~\")\n",
    "        print(e)\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "        return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos_sample_and_neig = pd.DataFrame()\n",
    "for key, value in modification_site_dic.items():\n",
    "    for chain, sites in value.items():\n",
    "        for site in sites:\n",
    "            pos_sample_and_neig = pd.concat([pos_sample_and_neig,n_nearest_neighbour(key,chain,site,1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, positive sites are ready. Negative sites are going to be picked. \n",
    "Right now, one pos - one neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neg_sample_and_neig = pd.DataFrame()\n",
    "for i in range(len(pos_sample_and_neig)):\n",
    "    result_step1 = One_residue_retrieval(pos_sample_and_neig.iloc[i,2],pos_sample_and_neig.iloc[i,0],pos_sample_and_neig.iloc[i,1])\n",
    "    \n",
    "    result_step2 = result_step1.groupby([\"ID\"]).first() #duplicate discard\n",
    "\n",
    "    result_step3 = result_step2[~result_step2.ID_2.isin(modification_site_dic[pos_sample_and_neig.iloc[i,0]][pos_sample_and_neig.iloc[i,1]])] # activate discard\n",
    "    #print(result_step3)\n",
    "    result_step4 = result_step3[result_step3[\"Res_2\"]==\"LYS\"]\n",
    "    #print(result_step4)\n",
    "    #print(result_step4.sample(1,random_state = 1))\n",
    "    neg_sample_and_neig = pd.concat([neg_sample_and_neig,result_step4.sample(1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Res_2 in neg_sample_and_neig is the negative sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sample_and_neig_pruned = pos_sample_and_neig.iloc[:,[0,1,2,3]].copy(deep=True)\n",
    "pos_sample_and_neig_pruned[\"type\"] = \"Pos\"\n",
    "pos_sample_and_neig_pruned.columns = ['pdbID', 'chain', 'ID', 'Res', 'type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_sample_and_neig_pruned = neg_sample_and_neig.iloc[:,[0,1,4,5]].copy(deep=True)\n",
    "neg_sample_and_neig_pruned[\"type\"] = \"Neg\"\n",
    "neg_sample_and_neig_pruned.columns = ['pdbID', 'chain', 'ID', 'Res', 'type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_sample = pd.concat([pos_sample_and_neig_pruned,neg_sample_and_neig_pruned])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbour_information_list = []\n",
    "for i in range(0,len(pos_neg_sample)):\n",
    "    neigh = n_nearest_neighbour(pos_neg_sample.iloc[i,0],pos_neg_sample.iloc[i,1],pos_neg_sample.iloc[i,2],5).iloc[:,5:8].values.flatten()\n",
    "    neighbour_information_list.append(np.insert(neigh,0,pos_neg_sample.iloc[i,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, make_scorer, confusion_matrix, \\\n",
    "    recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit, GroupKFold, cross_val_score\n",
    "from sklearn.metrics import auc, precision_recall_curve,accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import tree, svm, naive_bayes, neighbors\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer, OneHotEncoder,LabelEncoder\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {'decision_tree': tree.DecisionTreeClassifier(),\n",
    "        'naive_gaussian': naive_bayes.GaussianNB(),\n",
    "\n",
    "        'K_neighbor': neighbors.KNeighborsClassifier(),\n",
    "        'bagging_knn': BaggingClassifier(neighbors.KNeighborsClassifier(), max_samples=0.5, max_features=0.5),\n",
    "        'bagging_tree': BaggingClassifier(tree.DecisionTreeClassifier(), max_samples=0.5, max_features=0.5),\n",
    "        'random_forest': RandomForestClassifier(n_estimators=200),\n",
    "        'adaboost': AdaBoostClassifier(n_estimators=200),\n",
    "        'gradient_boost': GradientBoostingClassifier(n_estimators=50, learning_rate=1.0, max_depth=1, random_state=0),\n",
    "        'svm': svm.SVC(C=0.9,kernel='rbf',gamma='auto')\n",
    "        }\n",
    "#'svm': svm.SVC(probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
      "              handle_unknown='error', sparse=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "aminoAcidCodes = [\"ALA\",\"ARG\",\"ASN\",\"ASP\",\"CYS\",\"GLN\",\"GLY\",\"GLU\",\"HIS\",\"ILE\",\"LEU\",\"LYS\",\n",
    "                 \"MET\",\"PHE\",\"PRO\",\"PYL\",\"SER\",\"SEC\",\"THR\",\"TRP\",\"TYR\",\"VAL\"]\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(aminoAcidCodes)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit(integer_encoded)\n",
    "print(onehot_encoded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
      "              handle_unknown='error', sparse=False)\n"
     ]
    }
   ],
   "source": [
    "amino_acid_property_by_res = {\"ALA\":1,\"ILE\":1,\"LEU\":1,\"MET\":1,\"VAL\":1,\n",
    "                      \"PHE\":2, \"TRP\":2,\"TYR\":2,\n",
    "                       \"ASN\":3,\"CYS\":3,\"GLN\":3,\"SER\":3,\"THR\":3,\n",
    "                      \"ASP\":4,\"GLU\":4,\"ARG\":5,\"HIS\":5,\"LYS\":5,\"GLY\":6,\"PRO\":6}\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform([1,2,3,4,5,6])\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit(integer_encoded)\n",
    "print(onehot_encoded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbour_information_list = []\n",
    "for i in range(0,len(pos_neg_sample)):\n",
    "    neigh = n_nearest_neighbour(pos_neg_sample.iloc[i,0],pos_neg_sample.iloc[i,1],pos_neg_sample.iloc[i,2],1).iloc[:,5:8].values.flatten()\n",
    "    neighbour_information_list.append(np.insert(neigh,0,pos_neg_sample.iloc[i,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuan/anaconda3/envs/pdbPy3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/yuan/anaconda3/envs/pdbPy3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/yuan/anaconda3/envs/pdbPy3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/yuan/anaconda3/envs/pdbPy3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/yuan/anaconda3/envs/pdbPy3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/yuan/anaconda3/envs/pdbPy3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/yuan/anaconda3/envs/pdbPy3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/yuan/anaconda3/envs/pdbPy3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/yuan/anaconda3/envs/pdbPy3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/yuan/anaconda3/envs/pdbPy3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.591687449726\n",
      "decision_tree\n",
      "0.656243094237\n",
      "naive_gaussian\n",
      "0.509176694098\n",
      "naive_mul\n",
      "0.548862877268\n",
      "K_neighbor\n",
      "0.622952389852\n",
      "bagging_knn\n",
      "0.597847674802\n",
      "bagging_tree\n",
      "0.607180131353\n",
      "random_forest\n",
      "0.683932537874\n",
      "adaboost\n",
      "0.547591175018\n",
      "gradient_boost\n",
      "0.547948664686\n"
     ]
    }
   ],
   "source": [
    "train_dataset = []\n",
    "for each_res in neighbour_information_list:\n",
    "    one_res_data = []\n",
    "    for element in each_res:\n",
    "        if isinstance(element,str):\n",
    "            one_res_data.extend(onehot_encoded.transform([[amino_acid_property_by_res[element]-1]])[0].tolist())\n",
    "        else:\n",
    "            one_res_data.append(element)\n",
    "    train_dataset.append(one_res_data)\n",
    "wrong_sample = []\n",
    "for i in range(0,len(train_dataset)):\n",
    "    if(len(train_dataset[i])<1):\n",
    "        wrong_sample.append(i)\n",
    "\n",
    "y_label =[1 for x in range(0,len(pos_sample_and_neig_pruned))]\n",
    "y_label.extend([2 for i in range(0,len(neg_sample_and_neig_pruned))])\n",
    "\n",
    "final_y_label = [y_label[i] for i in range(0,len(pos_neg_sample)) if i not in wrong_sample]\n",
    "final_y_label = np.asarray(final_y_label)\n",
    "shuffle_y_label = shuffle(final_y_label,random_state=0)\n",
    "\n",
    "final_train_dataset = [train_dataset[i] for i in range(0,len(pos_neg_sample)) if i not in wrong_sample]\n",
    "final_train_dataset = np.vstack(np.asarray(final_train_dataset))\n",
    "shuffle_train_dataset = shuffle(final_train_dataset,random_state=0)\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=3)\n",
    "# for train, test in skf.split(shuffle_train_dataset,shuffle_y_label):\n",
    "#     for clf in clfs:\n",
    "#         clfs[clf].fit(shuffle_train_dataset[train],shuffle_y_label[train])\n",
    "#         conf_mat = confusion_matrix(clfs[clf].predict(shuffle_train_dataset[test]),shuffle_y_label[test])\n",
    "#         print(clf)\n",
    "#         print(accuracy_score(clfs[clf].predict(shuffle_train_dataset[test]),shuffle_y_label[test]))\n",
    "\n",
    "for clf in clfs:\n",
    "    print(clf)\n",
    "    scores = cross_val_score(clfs[clf],shuffle_train_dataset,shuffle_y_label,cv=10)\n",
    "    print(sum(scores)/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After using using CD-HIT to remove redundant samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cd_hit_7 = pd.read_csv(\"retained_CDHIT_0.7_PTM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdbID</th>\n",
       "      <th>Chain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1ln4</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1lop</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1m63</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1m63</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1m63</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pdbID Chain\n",
       "0  1ln4     A\n",
       "1  1lop     A\n",
       "2  1m63     A\n",
       "3  1m63     B\n",
       "4  1m63     D"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd_hit_7.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 neighbours 1:1 = pos:neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sample_and_neig = pd.DataFrame()\n",
    "for key, value in modification_site_dic.items():\n",
    "    for chain, sites in value.items():\n",
    "        if chain in list(cd_hit_7[cd_hit_7[\"pdbID\"]==key][\"Chain\"]):\n",
    "            for site in sites:\n",
    "                neigh = n_nearest_neighbour_by_seq(key,chain,site,1)\n",
    "                if len(neigh) > 0:\n",
    "                    pos_sample_and_neig = pos_sample_and_neig.append(neigh.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sample_and_neig = pos_sample_and_neig[neigh.columns]\n",
    "pos_sample_and_neig = pos_sample_and_neig.astype({\"ID_1\":int,\"ID_2\":int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_sample_and_neig = pd.DataFrame()\n",
    "for i in range(len(pos_sample_and_neig)):\n",
    "    result_step1 = One_residue_retrieval(pos_sample_and_neig.iloc[i,2],pos_sample_and_neig.iloc[i,0],pos_sample_and_neig.iloc[i,1])\n",
    "    result_step2 = result_step1.groupby([\"ID\"]).first() #duplicate discard\n",
    "    result_step3 = result_step2[~result_step2.ID_2.isin(modification_site_dic[pos_sample_and_neig.iloc[i,0]][pos_sample_and_neig.iloc[i,1]])] # activate discard\n",
    "    result_step4 = result_step3[result_step3[\"Res_2\"]==\"LYS\"]\n",
    "    neg_sample_and_neig = pd.concat([neg_sample_and_neig,result_step4.sample(1,replace = False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sample_and_neig_pruned = pos_sample_and_neig.iloc[:,[0,1,2,3]].copy(deep=True)\n",
    "pos_sample_and_neig_pruned[\"type\"] = \"Pos\"\n",
    "pos_sample_and_neig_pruned.columns = ['pdbID', 'chain', 'ID', 'Res', 'type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_sample_and_neig_pruned = neg_sample_and_neig.iloc[:,[0,1,4,5]].copy(deep=True)\n",
    "neg_sample_and_neig_pruned[\"type\"] = \"Neg\"\n",
    "neg_sample_and_neig_pruned.columns = ['pdbID', 'chain', 'ID', 'Res', 'type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1036"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_sample_and_neig_pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_sample = pd.concat([pos_sample_and_neig_pruned,neg_sample_and_neig_pruned])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neighbour_information_list = []\n",
    "num_pos = 0\n",
    "num_neg = 0\n",
    "for i in range(0,len(pos_neg_sample)):\n",
    "    features = n_nearest_neighbour(pos_neg_sample.iloc[i,0],pos_neg_sample.iloc[i,1],\\\n",
    "                                       pos_neg_sample.iloc[i,2],60)\n",
    "    if not isinstance(features,list):\n",
    "        if pos_neg_sample.iloc[i,4] == \"Pos\":\n",
    "            if features.shape[0] > 0:\n",
    "                num_pos = num_pos + 1\n",
    "                neighbour_information_list.append(np.insert(features.iloc[:,5:8].values.flatten(),0,pos_neg_sample.iloc[i,3]))\n",
    "        else:\n",
    "            if features.shape[0] > 0:\n",
    "                num_neg = num_neg + 1\n",
    "                neighbour_information_list.append(np.insert(features.iloc[:,5:8].values.flatten(),0,pos_neg_sample.iloc[i,3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision_tree\n",
      "accuracy: 0.5554 roc: 0.5614 precision: 0.5531 recall: 0.5235\n",
      "naive_gaussian\n",
      "accuracy: 0.5170 roc: 0.5338 precision: 0.5127 recall: 0.6634\n",
      "K_neighbor\n",
      "accuracy: 0.5223 roc: 0.5287 precision: 0.5211 recall: 0.5524\n",
      "bagging_knn\n",
      "accuracy: 0.5326 roc: 0.5739 precision: 0.5315 recall: 0.5933\n",
      "bagging_tree\n",
      "accuracy: 0.5637 roc: 0.5862 precision: 0.5582 recall: 0.6674\n",
      "random_forest\n",
      "accuracy: 0.5968 roc: 0.6379 precision: 0.5796 recall: 0.6682\n",
      "adaboost\n",
      "accuracy: 0.5666 roc: 0.5766 precision: 0.5669 recall: 0.5632\n",
      "gradient_boost\n",
      "accuracy: 0.5437 roc: 0.5578 precision: 0.5454 recall: 0.5408\n",
      "svm\n",
      "accuracy: 0.6051 roc: 0.6051 precision: 0.5591 recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "train_dataset = []\n",
    "for each_res in neighbour_information_list:\n",
    "    one_res_data = []\n",
    "    i = 0\n",
    "    for element in each_res[1:]:\n",
    "        if isinstance(element,str):\n",
    "#             one_res_data.extend(onehot_encoded.transform([[amino_acid_property_by_res[element]-1]])[0].tolist())\n",
    "            pass\n",
    "        else:\n",
    "            one_res_data.append(element)\n",
    "            \n",
    "#         if isinstance(element,str):\n",
    "#             one_res_data.extend(onehot_encoded.transform([[amino_acid_property_by_res[element]-1]])[0].tolist())\n",
    "#         else:\n",
    "#             if i % 2 == 1:\n",
    "#                 one_res_data.append(element/50)\n",
    "#             i = i + 1    \n",
    "            \n",
    "\n",
    "    train_dataset.append(one_res_data)\n",
    "wrong_sample = []\n",
    "for i in range(0,len(train_dataset)):\n",
    "    if(len(train_dataset[i])<len(train_dataset[0])):\n",
    "        wrong_sample.append(i)\n",
    "\n",
    "y_label =[1 for x in range(0,num_pos)]\n",
    "y_label.extend([2 for i in range(0,num_neg)])\n",
    "\n",
    "final_y_label = [y_label[i] for i in range(0,num_neg+num_pos) if i not in wrong_sample]\n",
    "final_y_label = np.asarray(final_y_label)\n",
    "shuffle_y_label = shuffle(final_y_label,random_state=0)\n",
    "\n",
    "final_train_dataset = [train_dataset[i] for i in range(0,num_neg+num_pos) if i not in wrong_sample]\n",
    "final_train_dataset = np.vstack(np.asarray(final_train_dataset))\n",
    "shuffle_train_dataset = shuffle(final_train_dataset,random_state=0)\n",
    "\n",
    "for clf in clfs:\n",
    "    print(clf)\n",
    "    scores_acc = cross_val_score(clfs[clf],shuffle_train_dataset,shuffle_y_label,scoring='accuracy',n_jobs=5,cv=10)\n",
    "    scores_roc = cross_val_score(clfs[clf],shuffle_train_dataset,shuffle_y_label,scoring='roc_auc',n_jobs=5,cv=10)\n",
    "    scores_precision = cross_val_score(clfs[clf],shuffle_train_dataset,shuffle_y_label,scoring='precision',n_jobs=5,cv=10)\n",
    "    scores_recall = cross_val_score(clfs[clf],shuffle_train_dataset,shuffle_y_label,scoring='recall',n_jobs=5,cv=10)\n",
    "    print('accuracy:',\"{:.4f}\".format(sum(scores_acc)/10),'roc:',\"{:.4f}\".format(sum(scores_roc)/10), \\\n",
    "         'precision:',\"{:.4f}\".format(sum(scores_precision)/10),'recall:',\"{:.4f}\".format(sum(scores_recall)/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(final_train_dataset).to_csv(\"/mnt/HD1/download/PTM_60_data.txt\")\n",
    "pd.DataFrame(final_y_label).to_csv(\"/mnt/HD1/download/PTM_60_label.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE training & testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_sample = pd.concat([pos_sample_and_neig_pruned,neg_sample_and_neig_pruned])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdbID</th>\n",
       "      <th>chain</th>\n",
       "      <th>ID</th>\n",
       "      <th>Res</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>740417</th>\n",
       "      <td>3jzf</td>\n",
       "      <td>A</td>\n",
       "      <td>27</td>\n",
       "      <td>LYS</td>\n",
       "      <td>Pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777277</th>\n",
       "      <td>3jzf</td>\n",
       "      <td>A</td>\n",
       "      <td>124</td>\n",
       "      <td>LYS</td>\n",
       "      <td>Pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936647</th>\n",
       "      <td>1o8c</td>\n",
       "      <td>A</td>\n",
       "      <td>50</td>\n",
       "      <td>LYS</td>\n",
       "      <td>Pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988322</th>\n",
       "      <td>1o8c</td>\n",
       "      <td>A</td>\n",
       "      <td>209</td>\n",
       "      <td>LYS</td>\n",
       "      <td>Pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238230</th>\n",
       "      <td>2eck</td>\n",
       "      <td>A</td>\n",
       "      <td>13</td>\n",
       "      <td>LYS</td>\n",
       "      <td>Pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pdbID chain   ID  Res type\n",
       "740417   3jzf     A   27  LYS  Pos\n",
       "777277   3jzf     A  124  LYS  Pos\n",
       "936647   1o8c     A   50  LYS  Pos\n",
       "988322   1o8c     A  209  LYS  Pos\n",
       "1238230  2eck     A   13  LYS  Pos"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_neg_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuan/anaconda3/envs/pdbPy3/lib/python3.6/site-packages/pymysql/cursors.py:170: Warning: (1292, \"Truncated incorrect DOUBLE value: '102A'\")\n",
      "  result = self._query(query)\n",
      "/home/yuan/anaconda3/envs/pdbPy3/lib/python3.6/site-packages/pymysql/cursors.py:170: Warning: (1292, \"Truncated incorrect DOUBLE value: '105A'\")\n",
      "  result = self._query(query)\n",
      "/home/yuan/anaconda3/envs/pdbPy3/lib/python3.6/site-packages/pymysql/cursors.py:170: Warning: (1292, \"Truncated incorrect DOUBLE value: '115A'\")\n",
      "  result = self._query(query)\n"
     ]
    }
   ],
   "source": [
    "neighbour_information_list = []\n",
    "num_pos = 0\n",
    "num_neg = 0\n",
    "for i in range(0,len(pos_neg_sample)):\n",
    "    features = Get_FEATURE(pos_neg_sample.iloc[i,0],pos_neg_sample.iloc[i,1],\\\n",
    "                pos_neg_sample.iloc[i,2])\n",
    "    if pos_neg_sample.iloc[i,4] == \"Pos\":\n",
    "        if features.shape[0] > 0:\n",
    "            num_pos = num_pos + 1\n",
    "            neighbour_information_list.append([float(x) for x in features[\"feature\"].values[0].split(\",\")])\n",
    "    else:\n",
    "        if features.shape[0] > 0:\n",
    "            num_neg = num_neg + 1\n",
    "            neighbour_information_list.append([float(x) for x in features[\"feature\"].values[0].split(\",\")])\n",
    "        \n",
    "#     print( n_nearest_neighbour_by_seq(pos_neg_sample.iloc[i,0],pos_neg_sample.iloc[i,1],pos_neg_sample.iloc[i,2],2))\n",
    "#     neigh = n_nearest_neighbour_by_seq(pos_neg_sample.iloc[i,0],pos_neg_sample.iloc[i,1],pos_neg_sample.iloc[i,2],2).iloc[:,5:8].values.flatten()\n",
    "#     neighbour_information_list.append(np.insert(neigh,0,pos_neg_sample.iloc[i,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision_tree\n",
      "accuracy: 0.5570 roc: 0.5571 precision: 0.5621 recall: 0.5069\n",
      "naive_gaussian\n",
      "accuracy: 0.5097 roc: 0.5392 precision: 0.6243 recall: 0.0579\n",
      "K_neighbor\n",
      "accuracy: 0.5410 roc: 0.5549 precision: 0.5414 recall: 0.5445\n",
      "bagging_knn\n",
      "accuracy: 0.5338 roc: 0.5538 precision: 0.5431 recall: 0.5617\n",
      "bagging_tree\n",
      "accuracy: 0.5811 roc: 0.5733 precision: 0.5669 recall: 0.6768\n",
      "random_forest\n",
      "accuracy: 0.6043 roc: 0.6538 precision: 0.5922 recall: 0.6584\n",
      "adaboost\n",
      "accuracy: 0.5420 roc: 0.5572 precision: 0.5416 recall: 0.5396\n",
      "gradient_boost\n",
      "accuracy: 0.5184 roc: 0.5431 precision: 0.5183 recall: 0.5233\n",
      "svm\n",
      "accuracy: 0.6115 roc: 0.6116 precision: 0.5630 recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "train_dataset = neighbour_information_list\n",
    "# for each_res in neighbour_information_list:\n",
    "#     one_res_data = []\n",
    "#     for element in each_res[1:]:\n",
    "#         if isinstance(element,str):\n",
    "#             pass\n",
    "#             #one_res_data.extend(onehot_encoded.transform([[amino_acid_property_by_res[element]-1]])[0].tolist())\n",
    "#         else:\n",
    "#             one_res_data.append(element)\n",
    "#     train_dataset.append(one_res_data)\n",
    "wrong_sample = []\n",
    "for i in range(0,len(train_dataset)):\n",
    "    if(len(train_dataset[i])<470):\n",
    "        wrong_sample.append(i)\n",
    "\n",
    "y_label =[1 for x in range(0,num_pos)]\n",
    "y_label.extend([2 for i in range(0,num_neg)])\n",
    "\n",
    "final_y_label = [y_label[i] for i in range(0,num_neg+num_pos) if i not in wrong_sample]\n",
    "final_y_label = np.asarray(final_y_label)\n",
    "shuffle_y_label = shuffle(final_y_label,random_state=0)\n",
    "\n",
    "final_train_dataset = [train_dataset[i] for i in range(0,num_neg+num_pos) if i not in wrong_sample]\n",
    "final_train_dataset = np.vstack(np.asarray(final_train_dataset))\n",
    "shuffle_train_dataset = shuffle(final_train_dataset,random_state=0)\n",
    "\n",
    "for clf in clfs:\n",
    "    print(clf)\n",
    "    scores_acc = cross_val_score(clfs[clf],shuffle_train_dataset,shuffle_y_label,scoring='accuracy',n_jobs=5,cv=10)\n",
    "    scores_roc = cross_val_score(clfs[clf],shuffle_train_dataset,shuffle_y_label,scoring='roc_auc',n_jobs=5,cv=10)\n",
    "    scores_precision = cross_val_score(clfs[clf],shuffle_train_dataset,shuffle_y_label,scoring='precision',n_jobs=5,cv=10)\n",
    "    scores_recall = cross_val_score(clfs[clf],shuffle_train_dataset,shuffle_y_label,scoring='recall',n_jobs=5,cv=10)\n",
    "    print('accuracy:',\"{:.4f}\".format(sum(scores_acc)/10),'roc:',\"{:.4f}\".format(sum(scores_roc)/10), \\\n",
    "         'precision:',\"{:.4f}\".format(sum(scores_precision)/10),'recall:',\"{:.4f}\".format(sum(scores_recall)/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSSM training & testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbour_information_list = []\n",
    "num_pos = 0\n",
    "num_neg = 0\n",
    "for i in range(0,len(pos_neg_sample)):\n",
    "    features = Get_Neigh_PSSM(pos_neg_sample.iloc[i,0],pos_neg_sample.iloc[i,1],\\\n",
    "                pos_neg_sample.iloc[i,2],6)\n",
    "    if pos_neg_sample.iloc[i,4] == \"Pos\":\n",
    "        if features.shape[0] > 0:\n",
    "            num_pos = num_pos + 1\n",
    "            neighbour_information_list.append(list(features.iloc[:,5:25].values.flatten()))\n",
    "    else:\n",
    "        if features.shape[0] > 0:\n",
    "            num_neg = num_neg + 1\n",
    "            neighbour_information_list.append(list(features.iloc[:,5:25].values.flatten()))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision_tree\n",
      "accuracy: 0.5556 roc: 0.5524 precision: 0.5691 recall: 0.5450\n",
      "naive_gaussian\n",
      "accuracy: 0.5082 roc: 0.5228 precision: 0.5131 recall: 0.3444\n",
      "K_neighbor\n",
      "accuracy: 0.5364 roc: 0.5464 precision: 0.5370 recall: 0.5407\n",
      "bagging_knn\n",
      "accuracy: 0.5316 roc: 0.5606 precision: 0.5386 recall: 0.5228\n",
      "bagging_tree\n",
      "accuracy: 0.5630 roc: 0.5743 precision: 0.5698 recall: 0.6575\n",
      "random_forest\n",
      "accuracy: 0.5843 roc: 0.6150 precision: 0.5659 recall: 0.6690\n",
      "adaboost\n",
      "accuracy: 0.5263 roc: 0.5396 precision: 0.5284 recall: 0.5186\n",
      "gradient_boost\n",
      "accuracy: 0.5141 roc: 0.5355 precision: 0.5161 recall: 0.5185\n",
      "svm\n",
      "accuracy: 0.6082 roc: 0.6379 precision: 0.5698 recall: 0.8950\n"
     ]
    }
   ],
   "source": [
    "train_dataset = neighbour_information_list\n",
    "wrong_sample = []\n",
    "for i in range(0,len(train_dataset)):\n",
    "    if(len(train_dataset[i])<15):\n",
    "        wrong_sample.append(i)\n",
    "\n",
    "y_label =[1 for x in range(0,num_pos)]\n",
    "y_label.extend([2 for i in range(0,num_neg)])\n",
    "\n",
    "final_y_label = [y_label[i] for i in range(0,num_neg+num_pos) if i not in wrong_sample]\n",
    "final_y_label = np.asarray(final_y_label)\n",
    "shuffle_y_label = shuffle(final_y_label,random_state=0)\n",
    "\n",
    "final_train_dataset = [train_dataset[i] for i in range(0,num_neg+num_pos) if i not in wrong_sample]\n",
    "final_train_dataset = np.vstack(np.asarray(final_train_dataset))\n",
    "shuffle_train_dataset = shuffle(final_train_dataset,random_state=0)\n",
    "\n",
    "for clf in clfs:\n",
    "    print(clf)\n",
    "    scores_acc = cross_val_score(clfs[clf],shuffle_train_dataset,shuffle_y_label,scoring='accuracy',n_jobs=5,cv=10)\n",
    "    scores_roc = cross_val_score(clfs[clf],shuffle_train_dataset,shuffle_y_label,scoring='roc_auc',n_jobs=5,cv=10)\n",
    "    scores_precision = cross_val_score(clfs[clf],shuffle_train_dataset,shuffle_y_label,scoring='precision',n_jobs=5,cv=10)\n",
    "    scores_recall = cross_val_score(clfs[clf],shuffle_train_dataset,shuffle_y_label,scoring='recall',n_jobs=5,cv=10)\n",
    "    print('accuracy:',\"{:.4f}\".format(sum(scores_acc)/10),'roc:',\"{:.4f}\".format(sum(scores_roc)/10), \\\n",
    "         'precision:',\"{:.4f}\".format(sum(scores_precision)/10),'recall:',\"{:.4f}\".format(sum(scores_recall)/10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = neighbour_information_list\n",
    "wrong_sample = []\n",
    "for i in range(0,len(train_dataset)):\n",
    "    if(len(train_dataset[i])<15):\n",
    "        wrong_sample.append(i)\n",
    "\n",
    "y_label =[0 for x in range(0,num_pos)]\n",
    "y_label.extend([1 for i in range(0,num_neg)])\n",
    "\n",
    "final_y_label = [y_label[i] for i in range(0,num_neg+num_pos) if i not in wrong_sample]\n",
    "final_y_label = np.asarray(final_y_label)\n",
    "shuffle_y_label = shuffle(final_y_label,random_state=0)\n",
    "\n",
    "final_train_dataset = [train_dataset[i] for i in range(0,num_neg+num_pos) if i not in wrong_sample]\n",
    "final_train_dataset = np.vstack(np.asarray(final_train_dataset))\n",
    "shuffle_train_dataset = shuffle(final_train_dataset,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "for each_res in neighbour_information_list:\n",
    "    one_res_data = []\n",
    "    i = 0\n",
    "    for element in each_res[1:]:\n",
    "        if isinstance(element,str):\n",
    "            one_res_data.extend(onehot_encoded.transform([[amino_acid_property_by_res[element]-1]])[0].tolist())\n",
    "        else:\n",
    "            one_res_data.append(element)\n",
    "            \n",
    "#         if isinstance(element,str):\n",
    "#             pass\n",
    "#         else:\n",
    "#             if i % 2 == 1:\n",
    "#                 one_res_data.append(element)\n",
    "#             i = i + 1    \n",
    "            \n",
    "\n",
    "    train_dataset.append(one_res_data)\n",
    "wrong_sample = []\n",
    "for i in range(0,len(train_dataset)):\n",
    "    if(len(train_dataset[i])<len(train_dataset[0])):\n",
    "        wrong_sample.append(i)\n",
    "\n",
    "y_label =[0 for x in range(0,num_pos)]\n",
    "y_label.extend([1 for i in range(0,num_neg)])\n",
    "\n",
    "final_y_label = [y_label[i] for i in range(0,num_neg+num_pos) if i not in wrong_sample]\n",
    "final_y_label = np.asarray(final_y_label)\n",
    "shuffle_y_label = shuffle(final_y_label,random_state=0)\n",
    "\n",
    "final_train_dataset = [train_dataset[i] for i in range(0,num_neg+num_pos) if i not in wrong_sample]\n",
    "final_train_dataset = np.vstack(np.asarray(final_train_dataset))\n",
    "shuffle_train_dataset = shuffle(final_train_dataset,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(300, input_dim=260, activation='relu'))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(shuffle_train_dataset, shuffle_y_label, epochs=50, batch_size=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1881/1881 [==============================] - 0s 54us/step\n",
      "Accuracy: 99.68\n"
     ]
    }
   ],
   "source": [
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(shuffle_train_dataset, shuffle_y_label)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions with the model\n",
    "predictions = model.predict_classes(shuffle_train_dataset)\n",
    "# summarize the first 5 cases\n",
    "for i in range(5):\n",
    "\tprint('%s => %d (expected %d)' % (shuffle_train_dataset[i].tolist(), predictions[i], shuffle_y_label[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 590385714393151722\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 3946922988132687430\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "skf.get_n_splits(shuffle_train_dataset,shuffle_y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/208 [==============================] - 0s 290us/step\n",
      "Accuracy: 56.73\n",
      "208/208 [==============================] - 0s 272us/step\n",
      "Accuracy: 52.88\n",
      "207/207 [==============================] - 0s 257us/step\n",
      "Accuracy: 55.07\n",
      "207/207 [==============================] - 0s 296us/step\n",
      "Accuracy: 52.17\n",
      "207/207 [==============================] - 0s 283us/step\n",
      "Accuracy: 57.00\n",
      "207/207 [==============================] - 0s 270us/step\n",
      "Accuracy: 51.69\n",
      "207/207 [==============================] - 0s 276us/step\n",
      "Accuracy: 55.07\n",
      "207/207 [==============================] - 0s 287us/step\n",
      "Accuracy: 57.97\n",
      "207/207 [==============================] - 0s 274us/step\n",
      "Accuracy: 58.45\n",
      "207/207 [==============================] - 0s 293us/step\n",
      "Accuracy: 57.00\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in skf.split(shuffle_train_dataset,shuffle_y_label):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=48, activation='relu'))\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile the keras model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(shuffle_train_dataset[train_index], \\\n",
    "              shuffle_y_label[train_index], epochs=50, batch_size=20,verbose=0)\n",
    "    _, accuracy = model.evaluate(shuffle_train_dataset[test_index], shuffle_y_label[test_index]) \n",
    "    print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
